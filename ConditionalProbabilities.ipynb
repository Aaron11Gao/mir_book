{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Probabilities \n",
    "### George Tzanetakis, University of Victoria \n",
    "\n",
    "In this notebook we explore conditional probabilities using an example from music. Imagine that you have a collection of songs consisting of two genres: country and jazz. Some songs have lyrics and some have not i.e they are instrumental. It makes sense that the probability of a song being instrumental depends on whether the song is jazz or country. This can be modeled through conditional probabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Helper random variable class \n",
    "Define a helper random variable class based on the scipy discrete random variable functionality providing both numeric and symbolic RVs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np \n",
    "\n",
    "class Random_Variable: \n",
    "    \n",
    "    def __init__(self, name, values, probability_distribution): \n",
    "        self.name = name \n",
    "        self.values = values \n",
    "        self.probability_distribution = probability_distribution \n",
    "        if all(type(item) is np.int64 for item in values): \n",
    "            self.type = 'numeric'\n",
    "            self.rv = stats.rv_discrete(name = name, values = (values, probability_distribution))\n",
    "        elif all(type(item) is str for item in values): \n",
    "            self.type = 'symbolic'\n",
    "            self.rv = stats.rv_discrete(name = name, values = (np.arange(len(values)), probability_distribution))\n",
    "            self.symbolic_values = values \n",
    "        else: \n",
    "            self.type = 'undefined'\n",
    "    \n",
    "    def sample(self,size): \n",
    "        if (self.type =='numeric'): \n",
    "            return self.rv.rvs(size=size)\n",
    "        elif (self.type == 'symbolic'): \n",
    "            numeric_samples = self.rv.rvs(size=size)\n",
    "            mapped_samples = [self.values[x] for x in numeric_samples]\n",
    "            return mapped_samples \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simulate the generation process of conditianal probabilities by appropriately sampling from three random variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'country')\n",
      "('no', 'country')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('yes', 'country')\n",
      "('yes', 'country')\n",
      "('yes', 'country')\n",
      "('yes', 'country')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('yes', 'country')\n",
      "('yes', 'jazz')\n",
      "('yes', 'country')\n",
      "('yes', 'country')\n",
      "('yes', 'country')\n"
     ]
    }
   ],
   "source": [
    "# samples to generate \n",
    "num_samples = 1000\n",
    "\n",
    "## Prior probabilities of a song being jazz or country \n",
    "values = ['country', 'jazz']\n",
    "probs = [0.7, 0.3]\n",
    "genre = Random_Variable('genre',values, probs)\n",
    "\n",
    "# conditional probabilities of a song having lyrics or not given the genre \n",
    "values = ['no', 'yes']\n",
    "probs = [0.9, 0.1] \n",
    "lyrics_if_jazz = Random_Variable('lyrics_if_jazz', values, probs)\n",
    "\n",
    "values = ['no', 'yes']\n",
    "probs = [0.2, 0.8]\n",
    "lyrics_if_country = Random_Variable('lyrics_if_country', values, probs)\n",
    "\n",
    "# conditional generating proces first sample prior and then based on outcome \n",
    "# choose which conditional probability distribution to use \n",
    "\n",
    "random_lyrics_samples = [] \n",
    "for n in range(num_samples): \n",
    "    # the 1 below is to get one sample and the 0 to get the first item of the list of samples \n",
    "    random_genre_sample = genre.sample(1)[0]\n",
    "\n",
    "    # depending on the outcome of the genre sampling sample the appropriate \n",
    "    # conditional probability \n",
    "    if (random_genre_sample == 'jazz'): \n",
    "        random_lyrics_sample = (lyrics_if_jazz.sample(1)[0], 'jazz')\n",
    "    else: \n",
    "        random_lyrics_sample = (lyrics_if_country.sample(1)[0], 'country')\n",
    "    random_lyrics_samples.append(random_lyrics_sample)\n",
    "\n",
    "# output 1 item per line and output the first 20 samples \n",
    "for s in random_lyrics_samples[0:20]: \n",
    "    print(s) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have generated samples of whether the song has lyrics or not. Above I have also printed the associated genre label. In many probabilistic modeling problems some information is not available to the observer. For example we could be provided only the yes/no outcomes and the genres could be \"hidden\". \n",
    "\n",
    "Now let's use these generated samples to estimate probabilities of the model. Basically we pretend that we don't know the parameters and estimate them directly by frequency counting through the samples we generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('yes', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n",
      "('no', 'jazz')\n"
     ]
    }
   ],
   "source": [
    "# First only consider jazz samples \n",
    "jazz_samples = [x for x in random_lyrics_samples if x[1] == 'jazz']\n",
    "for s in jazz_samples[0:20]: \n",
    "    print(s) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have selected the samples that are jazz we can simply count the lyrics yes and lyrics no entries and divide them by the total number of jazz samples to get estimates of the conditional probabilities. Think about the relationships: we can use the data to estimate the parameters of a model (learning), we can use the model to generate samples (generation), and we can use the model to calculate probabilities for various events (inference). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8867924528301887 0.11320754716981132\n"
     ]
    }
   ],
   "source": [
    "\n",
    "est_no_if_jazz = len([x for x in jazz_samples if x[0] == 'no']) / len(jazz_samples)\n",
    "est_yes_if_jazz = len([x for x in jazz_samples if x[0] == 'yes']) / len(jazz_samples)\n",
    "print(est_no_if_jazz, est_yes_if_jazz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen in the slides that the probability of a song being jazz if we know that it is instrumental is 0.66. \n",
    "\\begin{equation}\n",
    "P(genre = jazz | hasLyrics = no) = \\frac{0.3 * 0.9}{0.3 * 0.9 + 0.7 * 0.2} = 0.66\n",
    "\\end{equation}\n",
    "\n",
    "This is based on our knowledge of probabilities. If we have some data we can also estimate this probability directly. This is called approximate inference in contrast to the exact inference of $0.66$. When problems become complicated exact inference can become too costly to compute while approximate inference can provide reasonable answers much faster. We will see that later when examining probabilistic graphical models. As you can see in this case both the exact and approximate inference probability estimates are relatively close.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6828087167070218\n"
     ]
    }
   ],
   "source": [
    "no_samples = [x for x in random_lyrics_samples if x[0] == 'no']\n",
    "est_jazz_if_no_lyrics = len([x for x in no_samples if x[1] == 'jazz']) / len(no_samples)\n",
    "print(est_jazz_if_no_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
